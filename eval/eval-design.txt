这是一篇设计文档。
其目的是为今后的测评奠定框架。

* 性能指标
只采集一些基本数据，其他统计量在统计分析的时候再产生。
不要让ropevm去做复杂计算，它只进行收集。
每个线程分别收集数据,将来既可以画合计的图,也可以分别作图.
就认为一条指令之用一个时钟周期。


空闲周期数 idle-cycle-count
繁忙周期数 busy-cycle-count

验证成功数 verify-ok-count
验证错误数 verify-mismatch-count
无可验证数 verify-empty-count
(后两者合计为验证失败数verify-failed-count)

确定模式周期数 cert-mode-cycle-count
推测模式周期数 spec-mode-cycle-count
rvp模式周期数 rvp-mode-cycle-count

** 其他指标
（这些指标我还没有想好怎么去用）


确定控制转移多少次？这个应当等于确定消息发送的数目。

在推测模式下等待多少周期？

发送推测消息多少条？
处理推测消息多少条？
召回推测消息多少条？

同步消息多少条?
异步消息多少条?

共产生多少个对象
共用了多少个线程
平均一个线程负责多少个对象

停机多少次，原因都是什么？每种原因所占比例。

消息队列的长度：最大长度，平均长度。
其中待处理部分的长度，待提交部分的长度。
多版本状态缓冲区中版本数(待提交状态快照的数目)

* 实施
建立专门用于测评的eval目录。
并将其至于版本控制之下，以后的测评在以前的基础上进行修改。
每投一篇文章，都要对源码树进行快照。


eval目录下的java程序与开发时所用的java程序之间是什么关系？

- eval下的java程序应该是已经稳定下来的程序。这个是必然的。
- eval下的java程序必须是出现在论文中的。其他东西会妨碍测评。

将被测程序复制到eval文件夹下。
文件夹名改为treeadd-1-2这种形式。
第一个数字是程序版本号，第二个数字是输入版本号。


在overview.txt中说明都对哪些程序进行了测试.不同的配置都是什么.

最好能这样：
在eval文件夹下，我运行一个名为start-eval的脚本。
该脚本自动地去运行各个目录下的程序，产生统计输出。
统计输出文件的格式应方便导入excel，导入后对应一张worksheet。

** 发表分支
以用为目的的程序有发布分支，以发表为目的的程序就该有发表分支。
这对于研究团队来说很有意义，不过现在先不整。

** 发表快照
发表分支的一个代替品是发表快照

* 输出文件的格式
其格式应方便导入excel
第一列 线程id
第二列 统计量
第三列 数值

首先要保证涵盖那四个图
加速比
繁忙和空闲比
验证成功率
各种模式所占时间比例


* ropevm对统计的支持
用命令行开关或环境变量控制是否进行统计。（默认为关闭）


统计数据收集在什么地方？

是否考虑以后的多os线程实现？
在多os线程方式下，
加速比要用秒表计时，但其他一些参数还是要通过统计的方式进行。
所以考虑一下也是好的，但不宜过分考虑。

就目前的单os线程实现方式来说，
输出是否放在一个文件中？
因为要方便导入excel，文件格式要规整，一个文件对应一个数据库table。
这样的话，不同类型的信息就不适合放到同一个文件中。

table：线程信息
字段：线程ID，项目，值


java代码的不同版本（）
java程序的不同输入（cmd）+虚拟机的不同配置参数（vmparams）


为了求出加速比，还得在串行模型下运行一遍。

一次运行产生如下文件：
统计输出文件名：profile.txt，其中包含线程线程表

非测评时运行，我也想能输出一些信息，如确定模式周期数，以便对变快变慢有个直观印象。
这个功能就叫summary。直接输出到控制台上。可通过开关或环境变量控制。

最终采集的数据中也要有summary中的部分信息。


* 两种probe方法
野路子：只probe客户代码
缺点：不甚精确

正规方式：全部统计
缺点：需要很多的脚手架代码，在虚拟机中，在客户代码中。现在已经支持。
正规方式下预加载客户程序用到的类。
因为相比客户代码，加载类的代码量非常大，严重影响性能统计，所以需要在统计之前预加载。
预加载哪些类呢？看看bin-javac目录下有哪些class文件就知道了。
对于内部类，用
Class.forName("List$ListEnumerator");
的形式
对于标准库中的类，用
Class.forName("java.util.Enumeration");
的形式。

对于miniclasspath中的替代类，也需要加载。


